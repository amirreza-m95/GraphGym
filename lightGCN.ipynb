{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from torch_geometric.utils import degree\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movie_path = 'ml-latest-small/movies.csv'\n",
    "rating_path = 'ml-latest-small/ratings.csv'\n",
    "user_path = 'ml-latest-small/users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "9724\n",
      "610\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv(rating_path)\n",
    "\n",
    "print(rating_df.head())\n",
    "\n",
    "print(len(rating_df['movieId'].unique()))\n",
    "print(len(rating_df['userId'].unique()))\n",
    "\n",
    "rating_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "9723\n"
     ]
    }
   ],
   "source": [
    "# perform encoding preprocessing to ensure that user_id nad item_id are both\n",
    "# in the range of [0, unique_count] so it won't cause out of bound issue when indexing embeddings\n",
    "\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
    "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)\n",
    "\n",
    "print(rating_df.userId.max())\n",
    "print(rating_df.movieId.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='rating'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_df.rating.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edges between users and movies\n",
    "def load_edge_csv(df,\n",
    "                  src_index_col,\n",
    "                  dst_index_col,\n",
    "                  link_index_col=None,\n",
    "                  rating_treshold=3):\n",
    "    edge_index = None\n",
    "    src = [user_id for user_id in df['userId']]\n",
    "    dst = [movie_id for movie_id in df['movieId']]\n",
    "\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_treshold\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = load_edge_csv(rating_df, 'userId', 'movieId', 'rating', rating_treshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 x 48580\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(edge_index)} x {len(edge_index[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9443, 9444, 9445]])\n",
      "torch.Size([2, 48580])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.LongTensor(edge_index)\n",
    "print(edge_index)\n",
    "print(edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we apply rating treshhold\n",
    "num_users = len(rating_df['userId'].unique())\n",
    "num_movies = len(rating_df['movieId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interactions = edge_index.shape[1]\n",
    "\n",
    "# split the edges of the graphs using a 80/10/10 ratio\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.2, random_state=1)\n",
    "\n",
    "val_indices, test_indices = train_test_split(test_indices, test_size=0.5, random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 610, num_movies: 9724, num_interactions: 48580\n",
      "train_edge_index: torch.Size([2, 38864])\n",
      "num_users + num_movies: 10334\n",
      "torch.Size([609])\n",
      "torch.Size([5676])\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_users: {num_users}, num_movies: {num_movies}, num_interactions: {num_interactions}\")\n",
    "print(f\"train_edge_index: {train_edge_index.size()}\")\n",
    "print(f\"num_users + num_movies: {num_users + num_movies}\")\n",
    "print(torch.unique(train_edge_index[0]).size())\n",
    "print(torch.unique(train_edge_index[1]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
    "    R = torch.zeros((num_users, num_movies))\n",
    "    \n",
    "# convert sparse coo format to dense format to get R matrix\n",
    "    for i in range(len(input_edge_index[0])):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "\n",
    "\n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros((num_users + num_movies, num_users + num_movies))\n",
    "    adj_mat[:num_users, num_users:] = R.clone()\n",
    "    adj_mat[num_users:, :num_users] = R_transpose.clone()\n",
    "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
    "    adj_mat_coo = adj_mat_coo.indices()\n",
    "    return adj_mat_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
    "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0],\n",
    "                                            col=input_edge_index[1],\n",
    "                                            sparse_sizes=(num_users + num_movies, num_users + num_movies))\n",
    "    adj_mat = sparse_input_edge_index.to_dense()\n",
    "    interact_mat = adj_mat[:num_users, num_users:]\n",
    "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
    "    return r_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from r_mat edge index to adj matirices edge index\n",
    "# so we can feed it to the GCN model\n",
    "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
    "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
    "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n",
      "        [  610,   612,   653,  ...,   183,   183,   330]])\n",
      "torch.Size([2, 77728])\n",
      "tensor([[    0,     0,     0,  ..., 10226, 10236, 10240],\n",
      "        [  615,   794,  2010,  ...,   317,   204,   413]])\n",
      "torch.Size([2, 9716])\n",
      "tensor([[    0,     0,     0,  ..., 10301, 10302, 10329],\n",
      "        [  811,  1086,  1095,  ...,   585,   585,   183]])\n",
      "torch.Size([2, 9716])\n"
     ]
    }
   ],
   "source": [
    "print(train_edge_index)\n",
    "print(train_edge_index.size())\n",
    "print(val_edge_index)\n",
    "print(val_edge_index.size())\n",
    "print(test_edge_index)\n",
    "print(test_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices([i for i in range(edges.size(0))], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim=64,\n",
    "                 K=3,\n",
    "                 add_self_loops=False):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.user_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim)\n",
    "\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "\n",
    "    def forward(self, edge_index: Tensor):\n",
    "        edge_index_norm = gcn_norm(edge_index= edge_index, add_self_loops=self.add_self_loops)\n",
    "        emb_0 = torch.cat([self.user_emb.weight, self.item_emb.weight])\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "        for k in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
    "            embs.append(emb_k)\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1)\n",
    "        user_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
    "        return user_emb_final, self.user_emb.weight, items_emb_final, self.item_emb.weight\n",
    "    def message(self, x_j: Tensor, norm: Tensor):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 3\n",
    "model = LightGCN(num_users=num_users, num_items=num_movies, embedding_dim=64, K=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final,\n",
    "             users_emb_0,\n",
    "             pos_items_emb_final,\n",
    "             pos_items_emb_0,\n",
    "             neg_items_emb_final,\n",
    "             neg_items_emb_0,\n",
    "             lambda_val):\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) + \n",
    "                             pos_items_emb_0.norm(2).pow(2) + \n",
    "                             neg_items_emb_0.norm(2).pow(2))\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=1)\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=1)\n",
    "\n",
    "    bpr_loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).sum()\n",
    "    loss = bpr_loss + reg_loss\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user_id = edge_index[0][i].item()\n",
    "        item_id = edge_index[1][i].item()\n",
    "        if user_id not in user_pos_items:\n",
    "            user_pos_items[user_id] = []\n",
    "        user_pos_items[user_id].append(item_id)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecallPrecision_ATK(groungTruth, r, k):\n",
    "    num_correct_pred = torch.sum(r, dim=-1)\n",
    "    user_num_liked = torch.Tensor([len(groungTruth[i]) for i in range(len(groungTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred / k)\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groungTruth, r, k):\n",
    "    assert len(r) == len(groungTruth)\n",
    "    test_matrix = torch.zeros((len(r),k))\n",
    "    for i, items in enumerate(groungTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i,:length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1 / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1 / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0] = 1\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wraper function to getevaluation metrics\n",
    "def get_metrics(model,\n",
    "                input_edge_index,\n",
    "                input_exclude_edge_indices,\n",
    "                k):\n",
    "    user_embedding = model.user_emb.weight\n",
    "    item_embedding = model.item_emb.weight\n",
    "\n",
    "    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "\n",
    "    exclude_edge_indices = [convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index) \\\n",
    "                            for exclude_edge_index in input_exclude_edge_indices]\n",
    "    \n",
    "    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "    rating = r_mat_rating \n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "    _, top_k_items = torch.topk(rating, k=k)\n",
    "    users = edge_index[0].unique()\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "    r = []\n",
    "    for user in users:\n",
    "        user_true_relevant_item = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in user_true_relevant_item, top_k_items[user]))\n",
    "        r.append\n",
    "\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "    recall, precision = RecallPrecision_ATK(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wraper function for evaluation model\n",
    "def evaluation(model,\n",
    "               edge_index,\n",
    "               exclude_edge_indices,\n",
    "               k,\n",
    "               lambda_val):\n",
    "    user_emb_final, user_emb_0, items_emb_final, items_emb_0 = model.forward(edge_index)\n",
    "    r_mat_edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index)\n",
    "    edges = structured_negative_sampling(r_mat_edge_index, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = user_emb_final[user_indices], user_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val)\n",
    "    recall, precision, ndcg = get_metrics(model, edge_index, exclude_edge_indices, k)\n",
    "    return loss, recall, precision, ndcg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=ITERS_PER_LR_DECAY, gamma=0.5)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs_for_bpr(model, input_edge_index):\n",
    "    user_emb_final, user_emb_0, items_emb_final, items_emb_0 = model.forward(input_edge_index)\n",
    "    edge_index_to_use = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, edge_index_to_use)\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "\n",
    "    users_emb_final, users_emb_0 = user_emb_final[user_indices], user_emb_0[user_indices]\n",
    "    pos_item_emb_final, pos_item_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_item_emb_final, neg_item_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    return users_emb_final, users_emb_0, pos_item_emb_final, pos_item_emb_0, neg_item_emb_final, neg_item_emb_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7703e922dcb24fb59fe30b4988f5a14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 22\u001b[0m     val_loss, val_recall, val_precision, val_ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_edge_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAMBDA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m     24\u001b[0m     val_recall_at_ks\u001b[38;5;241m.\u001b[39mappend(val_recall)\n",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(model, edge_index, exclude_edge_indices, k, lambda_val)\u001b[0m\n\u001b[1;32m     13\u001b[0m neg_items_emb_final, neg_items_emb_0 \u001b[38;5;241m=\u001b[39m items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val)\n\u001b[0;32m---> 15\u001b[0m recall, precision, ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_edge_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, recall, precision, ndcg\n",
      "Cell \u001b[0;32mIn[24], line 38\u001b[0m, in \u001b[0;36mget_metrics\u001b[0;34m(model, input_edge_index, input_exclude_edge_indices, k)\u001b[0m\n\u001b[1;32m     36\u001b[0m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray(r)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m recall, precision \u001b[38;5;241m=\u001b[39m RecallPrecision_ATK(test_user_pos_items_list, r, k)\n\u001b[0;32m---> 38\u001b[0m ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mNDCGatK_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_user_pos_items_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recall, precision, ndcg\n",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m, in \u001b[0;36mNDCGatK_r\u001b[0;34m(groungTruth, r, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mNDCGatK_r\u001b[39m(groungTruth, r, k):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(groungTruth)\n\u001b[1;32m      4\u001b[0m     test_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(r),k))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, items \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(groungTruth):\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_recall_at_ks = []\n",
    "\n",
    "for iter in tqdm(range(ITERATIONS)):\n",
    "    # forward pass\n",
    "    users_emb_final, users_emb_0, pos_item_emb_final, pos_item_emb_0, neg_item_emb_final, neg_item_emb_0 = get_embs_for_bpr(model, train_edge_index)\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_item_emb_final, pos_item_emb_0, neg_item_emb_final, neg_item_emb_0, LAMBDA)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_recall, val_precision, val_ndcg = evaluation(model, val_edge_index, [train_edge_index], 10, LAMBDA)\n",
    "            val_losses.append(val_loss)\n",
    "            val_recall_at_ks.append(val_recall)\n",
    "            print(f\"Validation loss: {val_loss}, Recall@10: {val_recall}, Precision@10: {val_precision}, NDCG@10: {val_ndcg}\")\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            val_losses.append(val_loss)\n",
    "            val_recall_at_ks.append(round(val_recall, 5))\n",
    "        model.train()\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter > 0:\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgymvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
